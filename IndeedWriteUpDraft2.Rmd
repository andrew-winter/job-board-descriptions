---
title: "Wrangle and analyze job descriptions from indeed.com"
author: "Andrew Winter"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Why process text in R?
R has a huge selection of inuitive, charismatic packages. It has immediate practical use for data analysis, and it pairs well for general-purpose applications. 

Analyzing word choice in job postings might be important for my own decision-making when it comes to roles and applications. Web scraping, organizing, and analyzing this text is easy with a few R packages.


```{r packages, message=FALSE}
# Load required packages
library(tidyverse)
library(rvest)
library(tidytext)
```


## Search terms
```{r url}
indeed_search <- paste0(
  'https://www.indeed.com/jobs?q=',
  paste(
    c('data', 'analyst', 'R', 'SQL', 'Python', 'Excel'), collapse = '%2C+'),
  '&l=Los+Angeles%2C+CA')

indeed_search
```


In my experience, using more search terms yields more results on Indeed. If I supply a base url of some analysis terms that I like, I can "page through" the results to collect lots of postings.


```{r html session}
sesh <- html_session(indeed_search)

sample_links <- sesh %>%
  read_html() %>%
  html_nodes('h2 a') %>%
  html_attr('href') %>%
  paste0('indeed.com', .)
```


```{r paging through test}
sesh %>%
  jump_to(paste0(indeed_search, '&start=20')) %>%
  read_html()
```


## Sample nodes to find
```{r tests}
jobs10 <- sample_links[10] %>%
  html_session() %>%
  read_html()

# Role description
jobs10 %>%
  html_nodes('.jobsearch-jobDescriptionText') %>%
  html_text()

# Role name
jobs10 %>%
  html_nodes('.jobsearch-JobInfoHeader-title') %>%
  html_text()

# Location
jobs10 %>%
  html_nodes('.jobsearch-DesktopStickyContainer-companyrating+ div') %>%
  html_text()

# Company/organization
jobs10 %>%
  html_nodes('div .icl-u-xs-mr--xs') %>%
  `[[`(1) %>%
  html_text()

# Alternative org name-- this one returns reviews, sometimes
jobs10 %>%
  html_nodes('.icl-u-lg-mr--sm') %>%
  html_text()
```



## Function to reduce copying and pasting
```{r udf}
safe_mine_text <- function(html_class, str_to_css){
  if ("xml_node" %in% class(html_class) |
      "xml_document" %in% class(html_class)) {
    html_class %>%
      html_nodes(str_to_css) %>%
      html_text()  
  } else {
    NA
  }
}


"
test_df <- tibble(
  role_title = test_nodeset %>%
    html_text('title') %>%
    str_replace_all('\n', ''),
  role_url = test_nodeset %>%
    html_attr('href') %>%
    paste0(base_url, .)
)
"

```


## Unnesting tokens
```{r tokens tests}
sample_desc <- jobs10 %>%
  safe_mine_text('.jobsearch-jobDescriptionText')

sample_tbl <- tibble(txt = sample_desc)


# Bullet points, incomplete sentences make unnesting sentences difficult
sample_tbl %>%
  unnest_tokens(sentence, txt, token = "sentences")

# Unnesting by new lines is interesting, but maybe not useful
sample_tbl %>%
  unnest_tokens(line, txt, token = "regex", pattern = "\n")


# Most likely to be useful, and relatively simple
sample_words <- sample_tbl %>%
  unnest_tokens(word, txt)


# But two word ngrams are useful too, for phrases
sample_tbl %>%
  unnest_tokens(ngram, txt, token = "ngrams", n = 2)
```


## Summarizing words
```{r}
sample_words %>%
  count(word, sort = TRUE)


# Do I need to remove any stop words?
sample_words %>%
  inner_join(stop_words) %>%
  count(word, sort = TRUE)

```


To limit filler words, I can use an "anti-join" to remove words like "and", "by", and "the". For some reason "r" (as in the R programming language) is included in the default stop words. I definitely want to look at mentions of R, so I'll remove this from the default stop words, along with a few others.


## Joining words
```{r}
stop_words <- stop_words %>%
  anti_join(tibble(word = c('r', 'problem', 'problems')))


notable_stuff <- tibble(word = c('r', 'data'))

sample_words %>%
  inner_join(notable_stuff)

```

## Old, similar to how it'll be organized later
```{r}
search_nodeset <- indeed_search %>%
  read_html() %>%
  html_nodes('a.jobtitle')

# the argument for html_nodes() is a CSS selector
# extract hyperlink elements whose class is 'jobtitle'
# the Chrome extension SelectorGadget is very useful for finding CSS selectors

search_nodeset

# this doesn't work exactly as intended chief
search_df <- tibble(
  role_title = search_nodeset %>%
    html_text('title') %>%
    str_replace_all('\n', ''),
  role_url = search_nodeset %>%
    html_attr('href') %>%
    paste0(indeed_search, .)
)

search_df
```
